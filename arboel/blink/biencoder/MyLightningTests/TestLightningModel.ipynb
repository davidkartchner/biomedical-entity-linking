{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17/Mar/2024 11:25:29] INFO - This is an info message.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../..')\n",
    "sys.path.append('..')\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "import logger\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim, nn, utils, Tensor\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "import lightning as L\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_transformers.tokenization_bert import BertTokenizer\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from datetime import datetime\n",
    "from typing import Optional, Union\n",
    "\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler) \n",
    "from pytorch_transformers.optimization import WarmupLinearSchedule \n",
    "from scipy.sparse.csgraph import minimum_spanning_tree \n",
    "# csgraph = compressed sparse graph\n",
    "from scipy.sparse import csr_matrix\n",
    "# csr_matrix = compressed sparse row matrices\n",
    "from collections import Counter \n",
    "\n",
    "import blink.biencoder.data_process_mult as data_process\n",
    "# import blink.biencoder.eval_cluster_linking as eval_cluster_linking\n",
    "import blink.candidate_ranking.utils as utils\n",
    "from blink.biencoder.biencoder import BiEncoderRanker\n",
    "from blink.common.optimizer import get_bert_optimizer\n",
    "from blink.common.params import BlinkParser\n",
    "\n",
    "from IPython import embed \n",
    "from tqdm import tqdm\n",
    "\n",
    "import logging\n",
    "\n",
    "# Configure the logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Now you can use logger.info()\n",
    "logger.info(\"This is an info message.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import blink.biencoder.eval_cluster_linking as eval_cluster_linking\n",
    "from special_partition.special_partition import cluster_linking_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LightningDataModule import ArboelDataModule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate / filter_by_context_doc_id / loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    reranker,\n",
    "    valid_dict_vecs, \n",
    "    valid_men_vecs, \n",
    "    # device, #no longer used\n",
    "    logger, \n",
    "    # knn,  #not even used\n",
    "    # n_gpu, \n",
    "    entity_data, \n",
    "    query_data,\n",
    "    silent=False, \n",
    "    use_types=False, \n",
    "    embed_batch_size=768, \n",
    "    force_exact_search=False, \n",
    "    probe_mult_factor=1,\n",
    "    within_doc=False, \n",
    "    context_doc_ids=None ):\n",
    "    '''\n",
    "    Description \n",
    "    -----------\n",
    "    1) Computes embeddings and indexes for entities and mentions. \n",
    "    2) Performs k-nearest neighbors (k-NN) search to establish relationships between them.\n",
    "    3) Constructs graphs based on these relationships.\n",
    "    4) Evaluates the model's accuracy by analyzing how effectively the model can link mentions to the correct entities.\n",
    "    \n",
    "    Parameters \n",
    "    ----------\n",
    "    reranker : BiEncoderRanker\n",
    "        NN-based ranking model\n",
    "    valid_dict_vec : list or ndarray\n",
    "        Ground truth dataset containing the entities\n",
    "    valid_men_vecs : list or ndarray\n",
    "        Dataset containing mentions\n",
    "    device : str\n",
    "        cpu or gpu\n",
    "    logger : 'Logger' object\n",
    "        Logging object used to record messages\n",
    "    knn : int\n",
    "        Number of neighbors\n",
    "    n_gpu : int\n",
    "        Number of gpu\n",
    "    entity_data : list or dict\n",
    "        Entities from the data\n",
    "    query_data : list or dict\n",
    "        Queries / mentions against which the entities are evaluated\n",
    "    silent=False : bool \n",
    "        When set to \"True\", likely suppresses the output or logging of progress updates to keep the console output clean.\n",
    "    use_types=False : bool\n",
    "        A boolean flag that indicates whether or not to use type-specific indexes for entities and mentions\n",
    "    embed_batch_size=128 : int\n",
    "        The batch size to use when processing embeddings.\n",
    "    force_exact_search=False : bool\n",
    "        force the embedding process to use exact search methods rather than approximate methods.\n",
    "    probe_mult_factor=1 : int\n",
    "        A multiplier factor used in index building for probing in case of approximate search (bigger = better but slower)\n",
    "    within_doc=False : bool\n",
    "        Boolean flag that indicates whether the evaluation should be constrained to within-document contexts\n",
    "    context_doc_ids=None : bool\n",
    "        This would be used in conjunction with within_doc to limit evaluations within the same document.\n",
    "    '''\n",
    "    torch.cuda.empty_cache() # Empty the CUDA cache to free up GPU memory\n",
    "    \n",
    "    n_entities = len(valid_dict_vecs) # total number of entities\n",
    "    n_mentions = len(valid_men_vecs) # total number of mentions\n",
    "    max_knn = 8 # max number of neighbors\n",
    "    \n",
    "    joint_graphs = {} # Store results of the NN search and distance between entities and mentions\n",
    "    \n",
    "    for k in [0, 1, 2, 4, 8]:\n",
    "        joint_graphs[k] = { #DD3\n",
    "            \"rows\": np.array([]),\n",
    "            \"cols\": np.array([]),\n",
    "            \"data\": np.array([]),\n",
    "            \"shape\": (n_entities + n_mentions, n_entities + n_mentions),\n",
    "        }\n",
    "        \n",
    "    \n",
    "    '1) Computes embeddings and indexes for entities and mentions. '\n",
    "    '''\n",
    "    This block is preparing the data for evaluation by transforming raw vectors into a format that can be efficiently used for retrieval and comparison operations\n",
    "    '''\n",
    "    if use_types: # corpus = entity data\n",
    "                  # corpus is a collection of entities, which is used to build type-specific search indexes if provided.\n",
    "        '''\n",
    "        With a Corpus : Multiple type-specific indexes are created, allowing for more targeted and efficient searches within specific categories of entities.\n",
    "        'dict_embeds' and 'men_embeds': The resulting entity and mention embeddings.\n",
    "        'dict_indexes' and 'men_indexes': Dictionary that will store search indexes (!= indices)for each unique entity type found in the corpus\n",
    "        'dict_idxs_by_type' and 'men_idxs_by_type': Dictionary to store indices of the corpus elements, grouped by their entity type.\n",
    "        !!! idxs = indices / indexes = indexes !!!\n",
    "        '''\n",
    "        logger.info(\"Eval: Dictionary: Embedding and building index\") # For entities\n",
    "        dict_embeds, dict_indexes, dict_idxs_by_type = data_process.embed_and_index(\n",
    "            reranker,\n",
    "            valid_dict_vecs,\n",
    "            encoder_type=\"candidate\",\n",
    "            # n_gpu=n_gpu,\n",
    "            corpus=entity_data, \n",
    "            force_exact_search=force_exact_search, \n",
    "            batch_size=embed_batch_size, \n",
    "            probe_mult_factor=probe_mult_factor, \n",
    "            )\n",
    "        logger.info(\"Eval: Queries: Embedding and building index\") # For mentions\n",
    "        men_embeds, men_indexes, men_idxs_by_type = data_process.embed_and_index(\n",
    "            reranker,\n",
    "            valid_men_vecs,\n",
    "            encoder_type=\"context\",\n",
    "            # n_gpu=n_gpu,\n",
    "            corpus=query_data,\n",
    "            force_exact_search=force_exact_search,\n",
    "            batch_size=embed_batch_size,\n",
    "            probe_mult_factor=probe_mult_factor,\n",
    "        )\n",
    "    else: # corpus = None\n",
    "        '''\n",
    "        Without a Corpus: A single, general index is created for all embeddings, suitable for broad searches across the entire dataset.\n",
    "        'dict_embeds' and 'men_embeds': The resulting entity and mention embeddings.\n",
    "        'dict_index' and 'men_index': Dictionary that will store search index\n",
    "        '''\n",
    "        logger.info(\"Eval: Dictionary: Embedding and building index\")\n",
    "        dict_embeds, dict_index = data_process.embed_and_index(\n",
    "            reranker,\n",
    "            valid_dict_vecs,\n",
    "            \"candidate\",\n",
    "            # n_gpu=n_gpu,\n",
    "            force_exact_search=force_exact_search,\n",
    "            batch_size=embed_batch_size,\n",
    "            probe_mult_factor=probe_mult_factor,\n",
    "        )\n",
    "        logger.info(\"Eval: Queries: Embedding and building index\")\n",
    "        men_embeds, men_index = data_process.embed_and_index(\n",
    "            reranker,\n",
    "            valid_men_vecs,\n",
    "            \"context\",\n",
    "            # n_gpu=n_gpu,\n",
    "            force_exact_search=force_exact_search,\n",
    "            batch_size=embed_batch_size,\n",
    "            probe_mult_factor=probe_mult_factor,\n",
    "        )\n",
    "\n",
    "\n",
    "    '2) Performs k-nearest neighbors (k-NN) search to establish relationships between mentions and entities.'\n",
    "    logger.info(\"Eval: Starting KNN search...\") # An informational message is logged to indicate that the k-NN search is starting.\n",
    "    # Fetch recall_k (default 16) knn entities for all mentions\n",
    "    # Fetch (k+1) NN mention candidates; fetching all mentions for within_doc to filter down later\n",
    "    n_men_to_fetch = len(men_embeds) if within_doc else max_knn + 1 # Number of mentions to fetch\n",
    "    if not use_types: # Only one index so only need one search\n",
    "        nn_ent_dists, nn_ent_idxs = dict_index.search(men_embeds, 1) #DD4/DD5 #return the distance and the indice of the closest entity for all mentions in men_embeds\n",
    "        nn_men_dists, nn_men_idxs = men_index.search(men_embeds, n_men_to_fetch) # return the distances and the indices of the k closest mentions for all mentions in men_embeds\n",
    "    else: #C Several indexes corresponding to the different entities in entity_data so we can use the specific search index\n",
    "        # DD6\n",
    "        # DD7\n",
    "        nn_ent_idxs = -1 * np.ones((len(men_embeds), 1), dtype=int) # Indice of the closest entity for all mentions in men_embeds\n",
    "        nn_ent_dists = -1 * np.ones((len(men_embeds), 1), dtype=\"float64\") # Distance of the closest entity for all mentions in men_embeds\n",
    "        nn_men_idxs = -1 * np.ones((len(men_embeds), n_men_to_fetch), dtype=int) # Indice of k closest mentions for all mentions in men_embeds\n",
    "        nn_men_dists = -1 * np.ones((len(men_embeds), n_men_to_fetch), dtype=\"float64\") # Distance of the k closest mentions for all mentions in men_embeds\n",
    "        for entity_type in men_indexes:\n",
    "            #CC3 Creates a new list only containing the mentions for which type = entity_types\n",
    "            men_embeds_by_type = men_embeds[men_idxs_by_type[entity_type]] # Only want to search the mentions that belongs to a specific type of entity.\n",
    "            # Returns the distance and the indice of the closest entity for all mentions in men_embeds by entity type\n",
    "            nn_ent_dists_by_type, nn_ent_idxs_by_type = dict_indexes[entity_type].search(men_embeds_by_type, 1) \n",
    "            nn_ent_idxs_by_type = np.array( #CC4 DD8\n",
    "                list( #DD9\n",
    "                    map( # lambda x : acts as a function\n",
    "                        lambda x: dict_idxs_by_type[entity_type][x], nn_ent_idxs_by_type\n",
    "                    ) # nn_ent_idxs_by_type is the iterable being processed by the map function\n",
    "                    # Each element within nn_ent_idxs_by_type is passed to the lambda function as x.\n",
    "                ) # map alone would return an object, that's why need a list\n",
    "            )\n",
    "            # Returns the distance and the indice of the k closest mentions for all mention in men_embeds by entity type\n",
    "            # Note that here we may not necessarily have k mentions in each entity type which is why we use min(k,len(men_embeds_by_type))\n",
    "            nn_men_dists_by_type, nn_men_idxs_by_type = men_indexes[entity_type].search(\n",
    "                men_embeds_by_type, min(n_men_to_fetch, len(men_embeds_by_type))\n",
    "            )\n",
    "            nn_men_idxs_by_type = np.array(\n",
    "                list(\n",
    "                    map(lambda x: men_idxs_by_type[entity_type][x], nn_men_idxs_by_type)\n",
    "                )\n",
    "            )\n",
    "            for i, idx in enumerate(men_idxs_by_type[entity_type]): #CC5\n",
    "                nn_ent_idxs[idx] = nn_ent_idxs_by_type[i]\n",
    "                nn_ent_dists[idx] = nn_ent_dists_by_type[i]\n",
    "                nn_men_idxs[idx][: len(nn_men_idxs_by_type[i])] = nn_men_idxs_by_type[i]\n",
    "                nn_men_dists[idx][: len(nn_men_dists_by_type[i])] = nn_men_dists_by_type[i]\n",
    "    logger.info(\"Eval: Search finished\") # An informational message is logged to indicate that the k-NN search is finished\n",
    "\n",
    "    '3) Constructs graphs based on these relationships.'\n",
    "    '''\n",
    "    nn_ent_dists contain information about distance of the closest entity\n",
    "    nn_ent_idxs contain information about indice of the closest entity\n",
    "    nn_men_dists contain information about distance of the k nearest mentions\n",
    "    nn_men_idxs contain information about indice of the k nearest mentions\n",
    "    - We can fill in the \"rows\" part (=start nodes) of the graph in the order of the mentions\n",
    "    - We can fill in the \"cols\" part (=end nodes) of the graph with nn_ent_idxs and nn_men_idxs\n",
    "    - We can fill in the \"data\" part (=weights) of the graph with nn_ent_dists and nn_men_dists\n",
    "    '''\n",
    "    logger.info(\"Eval: Building graphs\")\n",
    "    for men_query_idx, men_embed in enumerate(\n",
    "        tqdm(men_embeds, total=len(men_embeds), desc=\"Eval: Building graphs\")\n",
    "    ):\n",
    "        # Get nearest entity candidate\n",
    "        dict_cand_idx = nn_ent_idxs[men_query_idx][0] # Use of [0] to retrieve a scalar and not an 1D array\n",
    "        dict_cand_score = nn_ent_dists[men_query_idx][0]\n",
    "\n",
    "        # Filter candidates to remove -1s, mention query, within doc (if reqd.), and keep only the top k candidates\n",
    "        filter_mask_neg1 = nn_men_idxs[men_query_idx] != -1 # bool ndarray. Ex : np.array([True, False, True, False])\n",
    "        men_cand_idxs = nn_men_idxs[men_query_idx][filter_mask_neg1] # Only keep the elements != -1\n",
    "        men_cand_scores = nn_men_dists[men_query_idx][filter_mask_neg1]\n",
    "\n",
    "        if within_doc:\n",
    "            men_cand_idxs, wd_mask = filter_by_context_doc_id(\n",
    "                men_cand_idxs,\n",
    "                context_doc_ids[men_query_idx],\n",
    "                context_doc_ids,\n",
    "                return_numpy=True,\n",
    "            )\n",
    "            men_cand_scores = men_cand_scores[wd_mask]\n",
    "        \n",
    "        # Filter self-reference + limits the number of candidate to 'max_knn'\n",
    "        filter_mask = men_cand_idxs != men_query_idx\n",
    "        men_cand_idxs, men_cand_scores = (\n",
    "            men_cand_idxs[filter_mask][:max_knn],\n",
    "            men_cand_scores[filter_mask][:max_knn],\n",
    "        )\n",
    "\n",
    "        # Add edges to the graphs\n",
    "        for k in joint_graphs:\n",
    "            joint_graph = joint_graphs[k] # There is no \"s\" in \"joint_graph\", it's not the same ! \n",
    "            # Add mention-entity edge\n",
    "            joint_graph[\"rows\"] = np.append( # Mentions are offset by the total number of entities to differentiate mention nodes from entity nodes\n",
    "                joint_graph[\"rows\"], [n_entities + men_query_idx]\n",
    "            )  \n",
    "            joint_graph[\"cols\"] = np.append(joint_graph[\"cols\"], dict_cand_idx)\n",
    "            joint_graph[\"data\"] = np.append(joint_graph[\"data\"], dict_cand_score)\n",
    "            if k > 0:\n",
    "                # Add mention-mention edges\n",
    "                joint_graph[\"rows\"] = np.append(\n",
    "                    joint_graph[\"rows\"],\n",
    "                    [n_entities + men_query_idx] * len(men_cand_idxs[:k]), # creates an array where the starting node (current mention) is repeated len(men_cand_idxs[:k]) times\n",
    "                ) \n",
    "                joint_graph[\"cols\"] = np.append(\n",
    "                    joint_graph[\"cols\"], n_entities + men_cand_idxs[:k]\n",
    "                )\n",
    "                joint_graph[\"data\"] = np.append(\n",
    "                    joint_graph[\"data\"], men_cand_scores[:k]\n",
    "                )\n",
    "    \n",
    "    \"4) Evaluates the model's accuracy by analyzing how effectively the model can link mentions to the correct entities.\"    \n",
    "    \n",
    "    best_result = {'accuracy': 0}\n",
    "    \n",
    "    dict_acc = {}\n",
    "    max_eval_acc = -1.\n",
    "    for k in joint_graphs:\n",
    "        logger.info(f\"\\nEval: Graph (k={k}):\")\n",
    "        # Partition graph based on cluster-linking constraints (inference procedure)\n",
    "        partitioned_graph, clusters = eval_cluster_linking.partition_graph(\n",
    "            joint_graphs[k], n_entities, directed=True, return_clusters=True)\n",
    "        # Infer predictions from clusters\n",
    "        result = eval_cluster_linking.analyzeClusters(clusters, entity_data, query_data, k)\n",
    "        acc = float(result['accuracy'].split(' ')[0])\n",
    "        best_result['accuracy'] = acc if acc >= best_result['accuracy'] else best_result['accuracy']\n",
    "        dict_acc[f'k{k}'] = acc\n",
    "        max_eval_acc = max(acc, max_eval_acc)\n",
    "        logger.info(f\"Eval: accuracy for graph@k={k}: {acc}%\")\n",
    "    logger.info(f\"Eval: Best accuracy: {max_eval_acc}%\")\n",
    "    embed_and_index_dict = {'dict_embeds': dict_embeds, 'dict_indexes': dict_indexes, 'dict_idxs_by_type': dict_idxs_by_type} if use_types else {'dict_embeds': dict_embeds, 'dict_index': dict_index}\n",
    "    return max_eval_acc, dict_acc, embed_and_index_dict\n",
    "\n",
    "\n",
    "\n",
    "def filter_by_context_doc_id(mention_idxs, doc_id, doc_id_list, return_numpy=False):\n",
    "    '''\n",
    "    Description \n",
    "    -----------\n",
    "    Filters and returns mention indices that belong to a specific document identified by \"doc_id\".\n",
    "    Ensures that the analysis are constrained within the context of that particular document.\n",
    "    \n",
    "    Parameters \n",
    "    ----------\n",
    "    - mention_idxs : ndarray(int) of dim = (number of mentions)\n",
    "    Represents the indices of mentions\n",
    "    - doc_id : int \n",
    "    Indice of the target document\n",
    "    - doc_id_list : ndarray(int) of dim = (number of mentions)\n",
    "    Array of integers, where each element is a document ID associated with the corresponding mention in mention_idxs. \n",
    "    The length of doc_id_list should match the total number of mentions referenced in mention_idxs.\n",
    "    - return_numpy : bool\n",
    "    A flag indicating whether to return the filtered list of mention indices as a NumPy array. \n",
    "    If True, the function returns a NumPy array; otherwise, it returns a list\n",
    "    -------\n",
    "    Outputs: \n",
    "    - mask : ndarray(bool) of dim = (number of mentions)\n",
    "    Mask indicating where each mention's document ID (from doc_id_list) matches the target doc_id\n",
    "    - mention_idxs : \n",
    "    Only contains mention indices that belong to the target document (=doc_id).\n",
    "    '''\n",
    "    mask = [doc_id_list[i] == doc_id for i in mention_idxs]\n",
    "    if isinstance(mention_idxs, list): # Test if mention_idxs = list. Return a bool\n",
    "        mention_idxs = np.array(mention_idxs) \n",
    "    mention_idxs = mention_idxs[mask] # possible only if mention_idxs is an array, not a list\n",
    "    if not return_numpy:\n",
    "        mention_idxs = list(mention_idxs)\n",
    "    return mention_idxs, mask\n",
    "\n",
    "\n",
    "\n",
    "def loss_function(reranker, \n",
    "    params, \n",
    "    forward_output, \n",
    "    data_module, \n",
    "    n_entities, \n",
    "    knn_dict, \n",
    "    batch_context_inputs, \n",
    "    accumulate_grad_batches\n",
    "    ):\n",
    "    '''\n",
    "    Compute the loss function during the training.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    - reranker : BiEncoderRanker\n",
    "    NN-based ranking model\n",
    "    - params : dict\n",
    "    Contains most of the relevant keys for training (embed_batch_size, train_batch_size, n_gpu, force_exact_search etc...)\n",
    "    - forward_output : dict\n",
    "    Output of the forward() method\n",
    "    - data_module : Instance of ArboelDataModule class\n",
    "    - n_entities : int\n",
    "    Total number of entities\n",
    "    - knn_dict : int (self.knn_dict = self.hparams[\"knn\"]//2)\n",
    "    number of negative entities to fetch. It divides the k-nn evenly between entities and mentions \n",
    "    - accumulate_grad_batches : int\n",
    "    Number of steps to accumulate gradients\n",
    "    '''\n",
    "    \n",
    "    # Compute the loss\n",
    "    loss_dual_negs = loss_ent_negs = 0\n",
    "    # loss of a batch includes both negative mention and entity inputs (alongside positive examples ofc)\n",
    "    loss_dual_negs, _ = reranker(forward_output['context_inputs'], label_input=forward_output['label_inputs'], mst_data={\n",
    "        'positive_embeds': forward_output['positive_embeds'],\n",
    "        'negative_dict_inputs': forward_output['negative_dict_inputs'],\n",
    "        'negative_men_inputs': forward_output['negative_men_inputs']\n",
    "    }, pos_neg_loss=params[\"pos_neg_loss\"]) #A27\n",
    "    skipped_context_inputs = []\n",
    "    if forward_output['skipped'] > 0 and not params[\"within_doc_skip_strategy\"]: #A28\n",
    "        skipped_negative_dict_inputs = torch.tensor(\n",
    "            list(map(lambda x: data_module.entity_dict_vecs[x].numpy(), skipped_negative_dict_inputs)))\n",
    "        skipped_positive_embeds = []\n",
    "        for pos_idx in forward_output['skipped_positive_idxs']:\n",
    "            if pos_idx < n_entities:\n",
    "                pos_embed = reranker.encode_candidate(data_module.entity_dict_vecs[pos_idx:pos_idx + 1],\n",
    "                                                        requires_grad=True)\n",
    "            else:\n",
    "                pos_embed = reranker.encode_context(\n",
    "                    data_module.train_men_vecs[pos_idx - n_entities:pos_idx - n_entities + 1], requires_grad=True)\n",
    "            skipped_positive_embeds.append(pos_embed)\n",
    "        skipped_positive_embeds = torch.cat(skipped_positive_embeds)\n",
    "        skipped_context_inputs = batch_context_inputs[~np.array(forward_output['context_inputs_mask'])]\n",
    "        skipped_context_inputs = skipped_context_inputs\n",
    "        skipped_label_inputs = torch.tensor([[1] + [0] * (knn_dict)] * len(skipped_context_inputs),\n",
    "                                    dtype=torch.float32)\n",
    "        #DD18 loss of a batch that only includes negative entity inputs.\n",
    "        loss_ent_negs, _ = reranker(skipped_context_inputs, label_input=skipped_label_inputs, mst_data={\n",
    "            'positive_embeds': skipped_positive_embeds,\n",
    "            'negative_dict_inputs': skipped_negative_dict_inputs,\n",
    "            'negative_men_inputs': None\n",
    "        }, pos_neg_loss=params[\"pos_neg_loss\"])\n",
    "            \n",
    "    # len(context_input) = Number of mentions in the batch that successfully found negative entities and mentions.\n",
    "    # len(skipped_context_inputs): Number of mentions in the batch that only found negative entities.\n",
    "    loss = ((loss_dual_negs * len(forward_output['context_inputs']) + loss_ent_negs * len(skipped_context_inputs)) / (len(forward_output['context_inputs']) + len(skipped_context_inputs))) / accumulate_grad_batches\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model Training'\n",
    "class LitArboel(L.LightningModule):\n",
    "    def __init__(\n",
    "        self, \n",
    "        params\n",
    "        ):\n",
    "        '''\n",
    "        - params : dict\n",
    "        Contains most of the relevant keys for training (embed_batch_size, train_batch_size, n_gpu, force_exact_search etc...)\n",
    "        - data_module : Instance of ArboelDataModule class\n",
    "        '''\n",
    "        super(LitArboel, self).__init__()\n",
    "        self.save_hyperparameters(params) #DD1\n",
    "        \n",
    "        self.reranker = BiEncoderRanker(params)\n",
    "        # self.tokenizer = self.reranker.tokenizer\n",
    "        self.model = self.reranker.model\n",
    "        \n",
    "    # def setup(self, stage: Optional[str] = None):\n",
    "    #     self.entity_dict_vecs = self.trainer.datamodule.entity_dict_vecs.to(self.device)\n",
    "    #     self.train_men_vecs = self.trainer.datamodule.train_men_vecs.to(self.device)\n",
    "        \n",
    "        \n",
    "    def forward(self, batch_context_inputs, candidate_idxs, n_gold, mention_idxs):\n",
    "        \"\"\"\n",
    "        Description\n",
    "        -----------\n",
    "        Processes a batch of input data to generate embeddings, and identifies positive and negative examples for training. \n",
    "        It handles the construction of mention-entity graphs, computes nearest neighbors, and organizes the data for subsequent loss calculation.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        - “batch_context_inputs” : Tensor\n",
    "            Tensor containing IDs of (mention + surrounding context) tokens. Shape: (batch_size, context_length) \n",
    "        - “candidate_idxs” : Tensor\n",
    "            Tensor with indices pointing to the entities in the entity dictionary that are considered correct labels for the mention. Shape: (batch_size, candidate_count)\n",
    "        - “n_gold” : Tensor\n",
    "            Number of labels (=entities) associated with the mention. Shape: (batch_size,)\n",
    "        - “mention_idx” : Tensor\n",
    "            Tensor containing a sequence of integers from 0 to N-1 (N = number of mentions in the dataset) serbing as a unique identifier for each mention.\n",
    "        \n",
    "        Return\n",
    "        ------\n",
    "        - label_inputs : Tensor\n",
    "            Tensor of binary labels indicating the correct candidates. Shape: (batch_size, 1 + knn_dict + knn_men), where 1 represents the positive example and the rest are negative examples.\n",
    "        - context_inputs : Tensor\n",
    "            Processed batch context inputs, filtered to remove mentions with no negative examples. Shape: (filtered_batch_size, context_length).\n",
    "        - negative_men_inputs : Tensor\n",
    "            Tensor of negative mention inputs. Shape: (filtered_batch_size * knn_men,)\n",
    "        - negative_dict_inputs : Tensor\n",
    "            Tensor of negative dictionary (entity) inputs. Shape: (filtered_batch_size * knn_dict,)\n",
    "        - positive_embeds : Tensor\n",
    "            Tensor of embeddings for the positive examples. Shape: (filtered_batch_size, embedding_dim)\n",
    "        - skipped : int \n",
    "            The number of mentions skipped due to lack of valid negative examples.\n",
    "        - skipped_positive_idxs : list(int)\n",
    "            List of indices for positive examples that were skipped.\n",
    "        - skipped_negative_dict_inputs :\n",
    "            Tensor of negative dictionary inputs for skipped examples. Shape may vary based on the number of skipped examples and available negative dictionary entries.\n",
    "        - context_inputs_mask : list(bool)\n",
    "            Mask indicating which entries in batch_context_inputs were retained after filtering out mentions with no negative examples.\n",
    "        \"\"\"\n",
    "        \n",
    "        # mentions within the batch\n",
    "        mention_embeddings = self.train_men_embeddings[mention_idxs.cpu()]\n",
    "        if len(mention_embeddings.shape) == 1:\n",
    "            mention_embeddings = np.expand_dims(mention_embeddings, axis=0)\n",
    "        # Convert Back to Tensor and Move to GPU\n",
    "        mention_embeddings = torch.from_numpy(mention_embeddings).to(self.device)\n",
    "\n",
    "        positive_idxs = []\n",
    "        negative_dict_inputs = []\n",
    "        negative_men_inputs = []\n",
    "\n",
    "        skipped_positive_idxs = []\n",
    "        skipped_negative_dict_inputs = []\n",
    "\n",
    "        min_neg_mens = float('inf')\n",
    "        skipped = 0\n",
    "        context_inputs_mask = [True]*len(batch_context_inputs)\n",
    "        \n",
    "        'IV.4.B) For each mention within the batch'\n",
    "        # For each mention within the batch\n",
    "        for m_embed_idx, m_embed in enumerate(mention_embeddings):\n",
    "            mention_idx = int(mention_idxs[m_embed_idx])\n",
    "            #CC11 ground truth entities of the mention \"mention_idx\"\n",
    "            gold_idxs = set(self.trainer.datamodule.train_processed_data[mention_idx]['label_idxs'][:n_gold[m_embed_idx]])\n",
    "            \n",
    "            # TEMPORARY: Assuming that there is only 1 gold label, TODO: Incorporate multiple case\n",
    "            assert n_gold[m_embed_idx] == 1\n",
    "\n",
    "            if mention_idx in self.gold_links:\n",
    "                gold_link_idx = self.gold_links[mention_idx]\n",
    "            else:\n",
    "                'IV.4.B.a) Create the graph with positive edges'\n",
    "                # This block creates all the positive edges of the mention in this iteration\n",
    "                # Run MST on mention clusters of all the gold entities of the current query mention to find its positive edge\n",
    "                rows, cols, data, shape = [], [], [], (self.n_entities+self.n_mentions, self.n_entities+self.n_mentions)\n",
    "                seen = set()\n",
    "\n",
    "                # Set whether the gold edge should be the nearest or the farthest neighbor\n",
    "                sim_order = 1 if self.hparams[\"farthest_neighbor\"] else -1 #A26\n",
    "\n",
    "                for cluster_ent in gold_idxs:\n",
    "                    #CC12 IDs of all the mentions inside the gold cluster with entity id = \"cluster_ent\"\n",
    "                    cluster_mens = self.trainer.datamodule.train_gold_clusters[cluster_ent]\n",
    "\n",
    "                    if self.hparams[\"within_doc\"]:\n",
    "                        # Filter the gold cluster to within-doc\n",
    "                        cluster_mens, _ = filter_by_context_doc_id(cluster_mens,\n",
    "                                                                    self.trainer.datamodule.train_context_doc_ids[mention_idx],\n",
    "                                                                    self.trainer.datamodule.train_context_doc_ids)\n",
    "                    \n",
    "                    # weights for all the mention-entity links inside the cluster of the current mention\n",
    "                    to_ent_data = self.train_men_embeddings[cluster_mens] @ self.train_dict_embeddings[cluster_ent].T\n",
    "\n",
    "                    # weights for all the mention-mention links inside the cluster of the current mention\n",
    "                    to_men_data = self.train_men_embeddings[cluster_mens] @ self.train_men_embeddings[cluster_mens].T\n",
    "\n",
    "                    if self.hparams['gold_arbo_knn'] is not None:\n",
    "                        # Descending order of similarity if nearest-neighbor, else ascending order\n",
    "                        sorti = np.argsort(sim_order * to_men_data, axis=1)\n",
    "                        sortv = np.take_along_axis(to_men_data, sorti, axis=1)\n",
    "                        if self.hparams[\"rand_gold_arbo\"]:\n",
    "                            randperm = np.random.permutation(sorti.shape[1])\n",
    "                            sortv, sorti = sortv[:, randperm], sorti[:, randperm]\n",
    "\n",
    "                    for i in range(len(cluster_mens)):\n",
    "                        from_node = self.n_entities + cluster_mens[i]\n",
    "                        to_node = cluster_ent\n",
    "                        # Add mention-entity link\n",
    "                        rows.append(from_node)\n",
    "                        cols.append(to_node)\n",
    "                        data.append(-1 * to_ent_data[i])\n",
    "                        if self.hparams['gold_arbo_knn'] is None:\n",
    "                            # Add forward and reverse mention-mention links over the entire MST\n",
    "                            for j in range(i+1, len(cluster_mens)):\n",
    "                                to_node = self.n_entities + cluster_mens[j]\n",
    "                                if (from_node, to_node) not in seen:\n",
    "                                    score = to_men_data[i,j]\n",
    "                                    rows.append(from_node)\n",
    "                                    cols.append(to_node)\n",
    "                                    data.append(-1 * score) # Negatives needed for SciPy's Minimum Spanning Tree computation\n",
    "                                    seen.add((from_node, to_node))\n",
    "                                    seen.add((to_node, from_node))\n",
    "                        else:\n",
    "                            # Approximate the MST using <gold_arbo_knn> nearest mentions from the gold cluster\n",
    "                            added = 0\n",
    "                            approx_k = min(self.hparams['gold_arbo_knn']+1, len(cluster_mens))\n",
    "                            for j in range(approx_k):\n",
    "                                if added == approx_k - 1:\n",
    "                                    break\n",
    "                                to_node = self.n_entities + cluster_mens[sorti[i, j]]\n",
    "                                if to_node == from_node:\n",
    "                                    continue\n",
    "                                added += 1\n",
    "                                if (from_node, to_node) not in seen:\n",
    "                                    score = sortv[i, j]\n",
    "                                    rows.append(from_node)\n",
    "                                    cols.append(to_node)\n",
    "                                    data.append(\n",
    "                                        -1 * score)  # Negatives needed for SciPy's Minimum Spanning Tree computation\n",
    "                                    seen.add((from_node, to_node))\n",
    "\n",
    "                'IV.4.B.b) Fine tuning with inference procedure to get a mst'\n",
    "                # Creates MST with entity constraint (inference procedure)\n",
    "                csr = csr_matrix((-sim_order * np.array(data), (rows, cols)), shape=shape)\n",
    "                # Note: minimum_spanning_tree expects distances as edge weights\n",
    "                mst = minimum_spanning_tree(csr).tocoo()\n",
    "                # Note: cluster_linking_partition expects similarities as edge weights # Convert directed to undirected graph\n",
    "                rows, cols, data = cluster_linking_partition(np.concatenate((mst.row, mst.col)), # cluster_linking_partition is imported from eval_cluster_linking\n",
    "                                                                np.concatenate((mst.col, mst.row)),\n",
    "                                                                np.concatenate((sim_order * mst.data, sim_order * mst.data)),\n",
    "                                                                self.n_entities,\n",
    "                                                                directed=True,\n",
    "                                                                silent=True)\n",
    "                assert np.array_equal(rows - self.n_entities, cluster_mens)\n",
    "                \n",
    "                for i in range(len(rows)):\n",
    "                    men_idx = rows[i] - self.n_entities\n",
    "                    if men_idx in self.gold_links:\n",
    "                        continue\n",
    "                    assert men_idx >= 0\n",
    "                    add_link = True\n",
    "                    # Store the computed positive edges for the mentions in the clusters only if they have the same gold entities as the query mention\n",
    "                    for l in self.trainer.datamodule.train_processed_data[men_idx]['label_idxs'][:self.trainer.datamodule.train_processed_data[men_idx]['n_labels']]:\n",
    "                        if l not in gold_idxs:\n",
    "                            add_link = False\n",
    "                            break\n",
    "                    if add_link:\n",
    "                        self.gold_links[men_idx] = cols[i]\n",
    "                gold_link_idx = self.gold_links[mention_idx]\n",
    "                \n",
    "            'IV.4.B.c) Retrieve the pre-computed nearest neighbors'\n",
    "            knn_dict_idxs = self.dict_nns[mention_idx]\n",
    "            knn_dict_idxs = knn_dict_idxs.astype(np.int64).flatten()\n",
    "            knn_men_idxs = self.men_nns[mention_idx][self.men_nns[mention_idx] != -1]\n",
    "            knn_men_idxs = knn_men_idxs.astype(np.int64).flatten()\n",
    "            if self.hparams['within_doc']:\n",
    "                knn_men_idxs, _ = filter_by_context_doc_id(knn_men_idxs,\n",
    "                                                        self.trainer.datamodule.train_context_doc_ids[mention_idx],\n",
    "                                                        self.trainer.datamodule.train_context_doc_ids, return_numpy=True)\n",
    "            'IV.4.B.d) Add negative examples'\n",
    "            neg_mens = list(knn_men_idxs[~np.isin(knn_men_idxs, np.concatenate([self.trainer.datamodule.train_gold_clusters[gi] for gi in gold_idxs]))][:self.knn_men])\n",
    "            # Track queries with no valid mention negatives\n",
    "            if len(neg_mens) == 0:\n",
    "                context_inputs_mask[m_embed_idx] = False\n",
    "                skipped_negative_dict_inputs += list(knn_dict_idxs[~np.isin(knn_dict_idxs, list(gold_idxs))][:self.knn_dict])\n",
    "                skipped_positive_idxs.append(gold_link_idx)\n",
    "                skipped += 1\n",
    "                continue\n",
    "            else:\n",
    "                min_neg_mens = min(min_neg_mens, len(neg_mens))\n",
    "            negative_men_inputs.append(knn_men_idxs[~np.isin(knn_men_idxs, np.concatenate([self.trainer.datamodule.train_gold_clusters[gi] for gi in gold_idxs]))][:self.knn_men])\n",
    "            negative_dict_inputs += list(knn_dict_idxs[~np.isin(knn_dict_idxs, list(gold_idxs))][:self.knn_dict])\n",
    "            # Add the positive example\n",
    "            positive_idxs.append(gold_link_idx)\n",
    "\n",
    "        \n",
    "        'IV.4.C) Skip this iteration if no suitable negative examples found'\n",
    "        if len(negative_men_inputs) == 0 :\n",
    "            return None #DD8 instead of continue\n",
    "        \n",
    "        # Sets the minimum number of negative mentions found across all processed mentions in the current batch\n",
    "        self.knn_men = min_neg_mens\n",
    "        \n",
    "        # This step ensures that each mention is compared against a uniform number of negative mentions\n",
    "        filtered_negative_men_inputs = []\n",
    "        for row in negative_men_inputs:\n",
    "            filtered_negative_men_inputs += list(row[:self.knn_men])\n",
    "        negative_men_inputs = filtered_negative_men_inputs\n",
    "\n",
    "        # Assertions for Data Integrity\n",
    "        assert len(negative_dict_inputs) == (len(mention_embeddings) - skipped) * self.knn_dict\n",
    "        assert len(negative_men_inputs) == (len(mention_embeddings) - skipped) * self.knn_men\n",
    "\n",
    "        self.total_skipped += skipped\n",
    "        self.total_knn_men_negs += self.knn_men\n",
    "\n",
    "        # Convert to tensors\n",
    "        negative_dict_inputs = torch.tensor(list(map(lambda x: self.trainer.datamodule.entity_dict_vecs[x].numpy(), negative_dict_inputs)))\n",
    "        negative_men_inputs = torch.tensor(list(map(lambda x: self.trainer.datamodule.train_men_vecs[x].numpy(), negative_men_inputs)))\n",
    "        \n",
    "        # Labels indicating the correct candidates. Used for computing loss.\n",
    "        positive_embeds = []\n",
    "        for pos_idx in positive_idxs:\n",
    "            if pos_idx < self.n_entities:\n",
    "                # print(\"Device of input tensors: entity_dict_vecs / train_men_vecs\", self.entity_dict_vecs.device, self.train_men_vecs.device)\n",
    "                # pos_embed = self.reranker.encode_candidate(self.trainer.datamodule.entity_dict_vecs.to(self.device)[pos_idx:pos_idx + 1], requires_grad=True)\n",
    "                pos_embed = self.reranker.encode_candidate(self.trainer.datamodule.entity_dict_vecs[pos_idx:pos_idx + 1], requires_grad=True)\n",
    "            else:\n",
    "                # print(\"Device of input tensors: entity_dict_vecs / train_men_vecs\", self.entity_dict_vecs.device, self.train_men_vecs.device)\n",
    "                pos_embed = self.reranker.encode_context(self.trainer.datamodule.train_men_vecs[pos_idx - self.n_entities:pos_idx - self.n_entities + 1], requires_grad=True)\n",
    "            positive_embeds.append(pos_embed)\n",
    "        positive_embeds = torch.cat(positive_embeds)\n",
    "        \n",
    "        # Remove mentions with no negative examples\n",
    "        context_inputs = batch_context_inputs[context_inputs_mask]\n",
    "        context_inputs = context_inputs\n",
    "        \n",
    "        # Tensor containing binary values that act as indicator variables in the paper:\n",
    "        # Contains Indicator variable such that I_{u,m_i} = 1 if(u,mi) ∈ E'_{m_i} and I{u,m_i} = 0 otherwise.\n",
    "        label_inputs = torch.tensor([[1]+[0]*(self.knn_dict+self.knn_men)]*len(context_inputs), dtype=torch.float32)\n",
    "        \n",
    "        return {'label_inputs':label_inputs, 'context_inputs' : context_inputs, \"negative_men_inputs\" : negative_men_inputs,\n",
    "                'negative_dict_inputs' : negative_dict_inputs, 'positive_embeds' : positive_embeds, 'skipped' : skipped,\n",
    "                'skipped_positive_idxs' : skipped_positive_idxs, 'skipped_negative_dict_inputs' : skipped_negative_dict_inputs,\n",
    "                'context_inputs_mask' : context_inputs_mask\n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        # batch = tuple(t.to(device) for t in batch) : automated in pytorch #DD5\n",
    "        \n",
    "        # Initialize the parameters\n",
    "        # batch is a subsample from tensor_dataset\n",
    "        batch_context_inputs, candidate_idxs, n_gold, mention_idxs = batch\n",
    "        \n",
    "        f = self.forward(batch_context_inputs, candidate_idxs, n_gold, mention_idxs)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = loss_function(self.reranker, \n",
    "            self.hparams, \n",
    "            f, \n",
    "            self.trainer.datamodule, \n",
    "            self.n_entities, \n",
    "            self.knn_dict, \n",
    "            batch_context_inputs, \n",
    "            self.trainer.accumulate_grad_batches\n",
    "        )\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def configure_optimizers(self): #DD2\n",
    "        \n",
    "        # Define optimizer\n",
    "        optimizer = get_bert_optimizer(\n",
    "        [self.model],\n",
    "        self.hparams[\"type_optimization\"],\n",
    "        self.hparams[\"learning_rate\"],\n",
    "        fp16=self.hparams.get(\"fp16\"),\n",
    "        )\n",
    "        \n",
    "        # Define scheduler\n",
    "        num_train_steps = int(len(self.trainer.datamodule.train_tensor_data) / self.hparams[\"train_batch_size\"] / self.trainer.accumulate_grad_batches) * self.trainer.max_epochs\n",
    "        num_warmup_steps = int(num_train_steps * self.hparams[\"warmup_proportion\"])\n",
    "\n",
    "        scheduler = WarmupLinearSchedule(\n",
    "            optimizer, warmup_steps=num_warmup_steps, t_total=num_train_steps,\n",
    "        )\n",
    "        logger.info(\" Num optimization steps = %d\" % num_train_steps)\n",
    "        logger.info(\" Num warmup steps = %d\", num_warmup_steps)\n",
    "        return [optimizer], [{'scheduler': scheduler, 'interval': 'step'}]\n",
    "\n",
    "\n",
    "\n",
    "    def on_train_start(self):\n",
    "        self.start_time = time.time()\n",
    "    \n",
    "    \n",
    "    # Don't need this for now\n",
    "    # def on_fit_start(self):\n",
    "    #     # Compute n_gpu once, at the start of training, and store it as an instance attribute\n",
    "    #     if self.trainer.devices is None:\n",
    "    #         self.n_gpu = 0\n",
    "    #     elif isinstance(self.trainer.devices, list):\n",
    "    #         self.n_gpu = len(self.trainer.devices)\n",
    "    #     elif isinstance(self.trainer.devices, int):\n",
    "    #         self.n_gpu = self.trainer.devices\n",
    "    #     else:\n",
    "    #         # For other configurations, such as auto-select or when specific GPUs are selected as a string\n",
    "    #         # It's safer to rely on the actual allocated devices by the trainer\n",
    "    #         self.n_gpu = len(self.trainer.accelerator_connector.parallel_devices)\n",
    "            \n",
    "            \n",
    "    def on_train_epoch_start(self):\n",
    "        # To do at the start of each epoch\n",
    "        self.tr_loss = 0\n",
    "        \n",
    "        'IV.1) Compute mention and entity embeddings and indexes at the start of each epoch'\n",
    "        # Compute mention and entity embeddings and indexes at the start of each epoch\n",
    "        if self.hparams['use_types']: # type-specific indexes \n",
    "            self.train_dict_embeddings, self.train_dict_indexes, self.dict_idxs_by_type = data_process.embed_and_index(\n",
    "                self.reranker, \n",
    "                self.trainer.datamodule.entity_dict_vecs, \n",
    "                encoder_type=\"candidate\", \n",
    "                # n_gpu=self.n_gpu, \n",
    "                corpus= self.trainer.datamodule.entity_dictionary, \n",
    "                force_exact_search= self.hparams['force_exact_search'], \n",
    "                batch_size= self.hparams['embed_batch_size'], \n",
    "                probe_mult_factor= self.hparams['probe_mult_factor']) #D11\n",
    "            self.train_men_embeddings, self.train_men_indexes, self.men_idxs_by_type = data_process.embed_and_index(\n",
    "                self.reranker, \n",
    "                self.trainer.datamodule.train_men_vecs, \n",
    "                encoder_type=\"context\", \n",
    "                #n_gpu=self.n_gpu, \n",
    "                corpus= self.trainer.datamodule.train_processed_data, \n",
    "                force_exact_search= self.hparams['force_exact_search'], \n",
    "                batch_size= self.hparams['embed_batch_size'], \n",
    "                probe_mult_factor= self.hparams['probe_mult_factor'])\n",
    "        \n",
    "        else: # general indexes\n",
    "            self.train_dict_embeddings, self.train_dict_index = data_process.embed_and_index(\n",
    "                self.reranker, \n",
    "                self.trainer.datamodule.entity_dict_vecs, \n",
    "                encoder_type=\"candidate\", \n",
    "                # n_gpu=self.n_gpu, \n",
    "                force_exact_search= \n",
    "                self.hparams['force_exact_search'], \n",
    "                batch_size= self.hparams['embed_batch_size'], \n",
    "                probe_mult_factor= self.hparams['probe_mult_factor'])\n",
    "            self.train_men_embeddings, self.train_men_index = data_process.embed_and_index(\n",
    "                self.reranker, \n",
    "                self.trainer.datamodule.train_men_vecs, \n",
    "                encoder_type=\"context\", \n",
    "                # n_gpu=self.n_gpu, \n",
    "                force_exact_search = self.hparams['force_exact_search'], \n",
    "                batch_size= self.hparams['embed_batch_size'], \n",
    "                probe_mult_factor= self.hparams['probe_mult_factor'])\n",
    "        \n",
    "        # Number of entities and mentions\n",
    "        self.n_entities = len(self.trainer.datamodule.entity_dictionary)\n",
    "        self.n_mentions = len(self.trainer.datamodule.train_processed_data)\n",
    "        \n",
    "        # Store golden MST links\n",
    "        self.gold_links = {}\n",
    "        # Calculate the number of negative entities and mentions to fetch # Divides the k-nn evenly between entities and mentions\n",
    "        self.knn_dict = self.hparams[\"knn\"]//2\n",
    "        self.knn_men = self.hparams[\"knn\"] - self.knn_dict\n",
    "        \n",
    "        'IV.3) knn search : indice and distance of k closest mentions and entities'\n",
    "        logger.info(\"Starting KNN search...\")\n",
    "        # INFO: Fetching all sorted mentions to be able to filter to within-doc later=\n",
    "        n_men_to_fetch = len(self.train_men_embeddings) if self.hparams[\"use_types\"] else self.knn_men + self.trainer.datamodule.max_gold_cluster_len\n",
    "        n_ent_to_fetch = self.knn_dict + 1 # +1 accounts for the possibility of self-reference\n",
    "        if not self.hparams[\"use_types\"]:\n",
    "            _, self.dict_nns = self.train_dict_index.search(self.train_men_embeddings, n_ent_to_fetch)\n",
    "            _, self.men_nns = self.train_men_index.search(self.train_men_embeddings, n_men_to_fetch)\n",
    "        else:\n",
    "            self.dict_nns = -1 * np.ones((len(self.train_men_embeddings), n_ent_to_fetch))\n",
    "            self.men_nns = -1 * np.ones((len(self.train_men_embeddings), n_men_to_fetch))\n",
    "            for entity_type in self.train_men_indexes:\n",
    "                self.men_embeds_by_type = self.train_men_embeddings[self.men_idxs_by_type[entity_type]]\n",
    "                _, self.dict_nns_by_type = self.train_dict_indexes[entity_type].search(self.men_embeds_by_type, n_ent_to_fetch)\n",
    "                _, self.men_nns_by_type = self.train_men_indexes[entity_type].search(self.men_embeds_by_type, min(n_men_to_fetch, len(self.men_embeds_by_type)))\n",
    "                self.dict_nns_idxs = np.array(list(map(lambda x: self.dict_idxs_by_type[entity_type][x], self.dict_nns_by_type)))\n",
    "                self.men_nns_idxs = np.array(list(map(lambda x: self.men_idxs_by_type[entity_type][x], self.men_nns_by_type)))\n",
    "                for i, idx in enumerate(self.men_idxs_by_type[entity_type]):\n",
    "                    self.dict_nns[idx] = self.dict_nns_idxs[i]\n",
    "                    self.men_nns[idx][:len(self.men_nns_idxs[i])] = self.men_nns_idxs[i]\n",
    "        logger.info(\"Search finished\")\n",
    "        \n",
    "        self.total_skipped = self.total_knn_men_negs = 0\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        # To do at the end of each epoch\n",
    "        # May not need it \n",
    "        pass\n",
    "    \n",
    "    def on_after_backward(self): #DD11\n",
    "        # After .backward()\n",
    "        if (self.trainer.global_step + 1) % self.trainer.accumulate_grad_batches == 0:\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                self.parameters(), self.trainer.grad_clip_norm\n",
    "            )\n",
    "            \n",
    "    # RR2 : Most of the info is already in the Trainer's callback        \n",
    "    # def on_train_batch_end(self, outputs, batch, batch_idx, dataloader_idx = 0):\n",
    "    #     # end of training batch\n",
    "    #     'IV.4.E) Information about the training (step, epoch, average_loss)'\n",
    "    #     n_print_iters = self.hparams[\"print_interval\"] * self.trainer.accumulate_grad_batches #29\n",
    "    #     if (batch_idx + 1) % n_print_iters == 0:\n",
    "    #         # DD13\n",
    "    #         self.log(\"train/average_loss\", self.tr_loss / n_print_iters, on_step=False, on_epoch=True, prog_bar=True)\n",
    "    #         if self.total_skipped > 0:\n",
    "    #             self.log(\"train/queries_without_negs\", self.total_skipped / n_print_iters, on_step=False, on_epoch=True)\n",
    "    #             self.log(\"train/negative_mentions_per_query\", self.total_knn_men_negs / n_print_iters, on_step=False, on_epoch=True)\n",
    "            \n",
    "    #         # Reset your tracking variables for the next interval\n",
    "    #         self.total_skipped = 0\n",
    "    #         self.total_knn_men_negs = 0\n",
    "    #         self.tr_loss = 0\n",
    "\n",
    "    #     # DD14\n",
    "    #     '''\n",
    "    #     # Regular checks on model performance against a validation dataset without interrupting the training more often than desired\n",
    "    #     if self.hparams[\"eval_interval\"] != -1: #A31\n",
    "    #         if (batch_idx + 1) % (self.hparams[\"eval_interval\"] * self.hparams[\"gradient_accumulation_steps\"]) == 0:\n",
    "    #             logger.info(\"Evaluation on the development dataset\")\n",
    "    #             evaluate(\n",
    "    #                 self.reranker, self.trainer.datamodule.entity_dict_vecs, self.trainer.datamodule.valid_men_vecs, device=self.device, logger=logger, knn=self.hparams[\"knn\"], n_gpu=self.n_gpu,\n",
    "    #                 entity_data=self.trainer.datamodule.entity_dictionary, query_data=self.valid_processed_data, silent=self.hparams[\"silent\"],\n",
    "    #                 use_types=self.hparams['use_types'] or self.hparams[\"use_types_for_eval\"], embed_batch_size=self.hparams[\"embed_batch_size\"],\n",
    "    #                 force_exact_search=self.hparams['use_types'] or self.hparams[\"use_types_for_eval\"] or self.hparams[\"force_exact_search\"],\n",
    "    #                 probe_mult_factor=self.hparams['probe_mult_factor'], within_doc=self.hparams['within_doc'],\n",
    "    #                 context_doc_ids=self.trainer.datamodule.valid_context_doc_ids\n",
    "    #             )\n",
    "    #             self.model.train()\n",
    "    #             logger.info(\"\\n\")\n",
    "    #     '''\n",
    "        \n",
    "    #     pass\n",
    "    \n",
    "    \n",
    "    def validation_step(self, batch, batch_idx): #DD14\n",
    "\n",
    "        max_acc, dict_acc, embed_and_index_dict = evaluate(\n",
    "            self.reranker, \n",
    "            self.trainer.datamodule.entity_dict_vecs, \n",
    "            self.trainer.datamodule.valid_men_vecs, \n",
    "            # device=self.device, \n",
    "            logger=logger, \n",
    "            # knn=self.hparams[\"knn\"], \n",
    "            # n_gpu=self.n_gpu,\n",
    "            entity_data=self.trainer.datamodule.entity_dictionary, \n",
    "            query_data=self.trainer.datamodule.valid_processed_data, \n",
    "            # silent=self.hparams[\"silent\"],\n",
    "            use_types=self.hparams['use_types'], #use_types=self.hparams['use_types'] or self.hparams[\"use_types_for_eval\"] \n",
    "            embed_batch_size=self.hparams[\"embed_batch_size\"],\n",
    "            force_exact_search=self.hparams['use_types'] or self.hparams[\"force_exact_search\"], #force_exact_search= self.hparams['use_types'] or use_types or self.hparams[\"use_types_for_eval\"] or self.hparams[\"force_exact_search\"]\n",
    "            probe_mult_factor=self.hparams['probe_mult_factor'], \n",
    "            within_doc=self.hparams['within_doc'],\n",
    "            context_doc_ids=self.trainer.datamodule.valid_context_doc_ids\n",
    "        )\n",
    "        self.log(\"max_acc\", max_acc, on_epoch=True)\n",
    "        for key, value in dict_acc.items():\n",
    "            self.log(f\"dict_acc_{key}\", value, on_epoch=True)\n",
    "        for key, value in dict_acc.items():\n",
    "            self.log(f\"embed_and_index_dict{key}\", value, on_epoch=True)\n",
    "        \n",
    "        \n",
    "    def test_step(self, batch, batch_idx): #DD14\n",
    "        max_acc, dict_acc, embed_and_index_dict = evaluate(\n",
    "            self.reranker, \n",
    "            self.trainer.datamodule.entity_dict_vecs, \n",
    "            self.trainer.datamodule.test_men_vecs, \n",
    "            # device=self.device, \n",
    "            logger=logger, \n",
    "            # knn=self.hparams[\"knn\"], \n",
    "            # n_gpu=self.n_gpu,\n",
    "            entity_data=self.trainer.datamodule.entity_dictionary, \n",
    "            query_data=self.trainer.datamodule.test_processed_data,\n",
    "            # silent=self.hparams[\"silent\"],\n",
    "            use_types=self.hparams['use_types'], #use_types=self.hparams['use_types'] or self.hparams[\"use_types_for_eval\"] \n",
    "            embed_batch_size=self.hparams[\"embed_batch_size\"],\n",
    "            force_exact_search=self.hparams['use_types'] or self.hparams[\"force_exact_search\"], #force_exact_search= self.hparams['use_types'] or use_types or self.hparams[\"use_types_for_eval\"] or self.hparams[\"force_exact_search\"]\n",
    "            probe_mult_factor=self.hparams['probe_mult_factor'], \n",
    "            within_doc=self.hparams['within_doc'],\n",
    "            context_doc_ids=self.trainer.datamodule.test_context_doc_ids\n",
    "        )\n",
    "        self.log(\"max_acc\", max_acc, on_epoch=True)\n",
    "        self.log(\"dict_acc\", dict_acc, on_epoch=True)\n",
    "        self.log(\"embedding_and_indexing\", embed_and_index_dict, on_epoch=True)\n",
    "        \n",
    "\n",
    "    def on_train_end(self):\n",
    "        execution_time = (time.time() - self.start_time) / 60\n",
    "        self.logger.info(f\"The training took {execution_time} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.trainer import Trainer\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home2/cye73/data/arboel/ncbi_disease\n"
     ]
    }
   ],
   "source": [
    "ontology = \"medic\"\n",
    "model = \"arboel\"\n",
    "dataset = \"ncbi_disease\"\n",
    "abs_path = \"/home2/cye73/data\"\n",
    "data_path = os.path.join(abs_path, model, dataset)\n",
    "print(data_path)\n",
    "abs_path2 = \"/home2/cye73/results\"\n",
    "model_output_path = os.path.join(abs_path2, model, dataset)\n",
    "\n",
    "ontology_type = \"umls\"\n",
    "umls_dir=\"/mitchell/entity-linking/2017AA/META/\"\n",
    "\n",
    "params_test = {\"model_output_path\" : model_output_path,\n",
    "               \"data_path\" : data_path,  \n",
    "               \"knn\" : 4,\n",
    "               \"use_types\" : False,\n",
    "               \"max_context_length\": 64 ,\n",
    "               \"max_cand_length\" : 64 ,\n",
    "               \"context_key\" : \"context\", # to specify context_left or context_right\n",
    "               \"debug\" : True,\n",
    "               \"gold_arbo_knn\": 4,\n",
    "               \"within_doc\" : True,\n",
    "               \"within_doc_skip_strategy\" : False,\n",
    "               \"batch_size\" : 128,#batch_size = embed_batch_size\n",
    "               \"train_batch_size\" : 128,\n",
    "               \"filter_unlabeled\" : False,\n",
    "               \"type_optimization\" : \"all\",\n",
    "               # 'additional_layers', 'top_layer', 'top4_layers', 'all_encoder_layers', 'all'\n",
    "               \"learning_rate\" : 3e-5,\n",
    "               \"warmup_proportion\" : 464,\n",
    "               \"fp16\" : False,\n",
    "               \"embed_batch_size\" : 128,\n",
    "               \"force_exact_search\" : True,\n",
    "               \"probe_mult_factor\" : 1,\n",
    "               \"pos_neg_loss\" : True,\n",
    "               \"use_types_for_eval\" : True,\n",
    "               \"drop_entities\" : False,\n",
    "               \"drop_set\" : False,\n",
    "               \"farthest_neighbor\" : True,\n",
    "               \"rand_gold_arbo\" : True,\n",
    "               \"bert_model\": 'michiyasunaga/BioLinkBERT-base',\n",
    "               \"out_dim\": 768 ,\n",
    "               \"pull_from_layer\":11, #11 for base and 23 for large\n",
    "               \"add_linear\":True,\n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = ArboelDataModule(params = params_test,\n",
    "                                ontology = ontology,\n",
    "                                dataset = dataset,\n",
    "                                ontology_type = ontology_type,\n",
    "                                umls_dir = umls_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitArboel(params = params_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Model checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint(\n",
    "    monitor='max_acc',  # Metric to monitor\n",
    "    dirpath=params_test[\"model_output_path\"],  # Directory to save the model\n",
    "    filename='{epoch}-{max_acc:.2f}',  # Saves the model with epoch and val_loss in the filename\n",
    "    save_top_k= 1,  # Number of best models to save; -1 means save all of them\n",
    "    mode='max',  # 'max' means the highest max_acc will be considered as the best model\n",
    "    verbose=True,  # Logs a message whenever a model checkpoint is saved\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/Mar/2024 16:20:00] INFO - GPU available: True (cuda), used: True\n",
      "[15/Mar/2024 16:20:00] INFO - TPU available: False, using: 0 TPU cores\n",
      "[15/Mar/2024 16:20:00] INFO - IPU available: False, using: 0 IPUs\n",
      "[15/Mar/2024 16:20:00] INFO - HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    max_epochs=2,\n",
    "    devices=[0, 1, 2, 3],\n",
    "    accelerator=\"gpu\",\n",
    "    strategy=\"ddp_notebook\",\n",
    "    enable_progress_bar=True,\n",
    "    # callbacks=[model_checkpoint],\n",
    "    log_every_n_steps=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/Mar/2024 16:20:02] INFO - Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/Mar/2024 16:20:02] INFO - Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/Mar/2024 16:20:02] INFO - Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/Mar/2024 16:20:02] INFO - Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "[15/Mar/2024 16:20:02] INFO - ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/datasets/load.py:1454: FutureWarning: The repository for bigbio/ncbi_disease contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/bigbio/ncbi_disease\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stored processed entity dictionary...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13189/13189 [00:00<00:00, 2553012.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max labels on one doc: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating correct mention format for train dataset: 100%|██████████| 5065/5065 [00:00<00:00, 10306.00it/s]\n",
      "Creating correct mention format for validation dataset: 100%|██████████| 780/780 [00:00<00:00, 302027.06it/s]\n",
      "Creating correct mention format for test dataset: 100%|██████████| 960/960 [00:00<00:00, 375469.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stored processed entity dictionary...\n",
      "Loading stored processed entity dictionary...Loading stored processed entity dictionary...Loading stored processed entity dictionary...\n",
      "\n",
      "\n",
      "Loading stored processed train data...\n",
      "Loading stored processed valid data...Loading stored processed train data...\n",
      "\n",
      "Loading stored processed train data...\n",
      "Loading stored processed valid data...\n",
      "Loading stored processed valid data...\n",
      "Loading stored processed train data...\n",
      "Loading stored processed valid data...\n",
      "[15/Mar/2024 16:20:06] INFO - within_doc\n",
      "[15/Mar/2024 16:20:06] INFO - within_doc\n",
      "[15/Mar/2024 16:20:06] INFO - within_doc\n",
      "[15/Mar/2024 16:20:06] INFO - within_doc\n",
      "[15/Mar/2024 16:20:06] INFO - Read 4783 train samples..\n",
      "[15/Mar/2024 16:20:06] INFO - Read 722 valid samples..\n",
      "[15/Mar/2024 16:20:06] INFO - Read 4783 train samples..\n",
      "[15/Mar/2024 16:20:06] INFO - Read 877 test samples..\n",
      "[15/Mar/2024 16:20:06] INFO - Read 4783 train samples..\n",
      "[15/Mar/2024 16:20:06] INFO - Read 722 valid samples..\n",
      "[15/Mar/2024 16:20:06] INFO - Read 4783 train samples..\n",
      "[15/Mar/2024 16:20:06] INFO - Read 722 valid samples..\n",
      "[15/Mar/2024 16:20:06] INFO - Read 877 test samples..\n",
      "[15/Mar/2024 16:20:06] INFO - Read 877 test samples..\n",
      "[15/Mar/2024 16:20:06] INFO - Read 722 valid samples..\n",
      "[15/Mar/2024 16:20:06] INFO - Read 877 test samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "INFO: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "INFO: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/Mar/2024 16:20:06] INFO - LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "[15/Mar/2024 16:20:06] INFO - LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "[15/Mar/2024 16:20:06] INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "[15/Mar/2024 16:20:06] INFO - LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "The following parameters will be optimized WITH decay:The following parameters will be optimized WITH decay:The following parameters will be optimized WITH decay:\n",
      "\n",
      "\n",
      "context_encoder.bert_model.embeddings.word_embeddings.weight , context_encoder.bert_model.embeddings.position_embeddings.weight , context_encoder.bert_model.embeddings.token_type_embeddings.weight , context_encoder.bert_model.embeddings.LayerNorm.weight , context_encoder.bert_model.encoder.layer.0.attention.self.query.weight , ...and 197 morecontext_encoder.bert_model.embeddings.word_embeddings.weight , context_encoder.bert_model.embeddings.position_embeddings.weight , context_encoder.bert_model.embeddings.token_type_embeddings.weight , context_encoder.bert_model.embeddings.LayerNorm.weight , context_encoder.bert_model.encoder.layer.0.attention.self.query.weight , ...and 197 morecontext_encoder.bert_model.embeddings.word_embeddings.weight , context_encoder.bert_model.embeddings.position_embeddings.weight , context_encoder.bert_model.embeddings.token_type_embeddings.weight , context_encoder.bert_model.embeddings.LayerNorm.weight , context_encoder.bert_model.encoder.layer.0.attention.self.query.weight , ...and 197 more\n",
      "\n",
      "\n",
      "The following parameters will be optimized WITHOUT decay:The following parameters will be optimized WITHOUT decay:The following parameters will be optimized WITHOUT decay:\n",
      "\n",
      "\n",
      "context_encoder.bert_model.embeddings.LayerNorm.bias , context_encoder.bert_model.encoder.layer.0.attention.self.query.bias , context_encoder.bert_model.encoder.layer.0.attention.self.key.bias , context_encoder.bert_model.encoder.layer.0.attention.self.value.bias , context_encoder.bert_model.encoder.layer.0.attention.output.dense.bias , ...and 191 morecontext_encoder.bert_model.embeddings.LayerNorm.bias , context_encoder.bert_model.encoder.layer.0.attention.self.query.bias , context_encoder.bert_model.encoder.layer.0.attention.self.key.bias , context_encoder.bert_model.encoder.layer.0.attention.self.value.bias , context_encoder.bert_model.encoder.layer.0.attention.output.dense.bias , ...and 191 morecontext_encoder.bert_model.embeddings.LayerNorm.bias , context_encoder.bert_model.encoder.layer.0.attention.self.query.bias , context_encoder.bert_model.encoder.layer.0.attention.self.key.bias , context_encoder.bert_model.encoder.layer.0.attention.self.value.bias , context_encoder.bert_model.encoder.layer.0.attention.output.dense.bias , ...and 191 more\n",
      "\n",
      "\n",
      "The following parameters will be optimized WITH decay:\n",
      "context_encoder.bert_model.embeddings.word_embeddings.weight , context_encoder.bert_model.embeddings.position_embeddings.weight , context_encoder.bert_model.embeddings.token_type_embeddings.weight , context_encoder.bert_model.embeddings.LayerNorm.weight , context_encoder.bert_model.encoder.layer.0.attention.self.query.weight , ...and 197 more[15/Mar/2024 16:20:06] INFO -  Num optimization steps = 2\n",
      "[15/Mar/2024 16:20:06] INFO -  Num optimization steps = 2\n",
      "[15/Mar/2024 16:20:06] INFO -  Num optimization steps = 2\n",
      "\n",
      "[15/Mar/2024 16:20:06] INFO -  Num warmup steps = 928\n",
      "[15/Mar/2024 16:20:06] INFO -  Num warmup steps = 928\n",
      "The following parameters will be optimized WITHOUT decay:[15/Mar/2024 16:20:06] INFO -  Num warmup steps = 928\n",
      "\n",
      "context_encoder.bert_model.embeddings.LayerNorm.bias , context_encoder.bert_model.encoder.layer.0.attention.self.query.bias , context_encoder.bert_model.encoder.layer.0.attention.self.key.bias , context_encoder.bert_model.encoder.layer.0.attention.self.value.bias , context_encoder.bert_model.encoder.layer.0.attention.output.dense.bias , ...and 191 more\n",
      "[15/Mar/2024 16:20:06] INFO -  Num optimization steps = 2\n",
      "[15/Mar/2024 16:20:06] INFO -  Num warmup steps = 928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: \n",
      "  | Name     | Type            | Params\n",
      "---------------------------------------------\n",
      "0 | reranker | BiEncoderRanker | 217 M \n",
      "1 | model    | BiEncoderModule | 217 M \n",
      "---------------------------------------------\n",
      "217 M     Trainable params\n",
      "0         Non-trainable params\n",
      "217 M     Total params\n",
      "870.586   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/Mar/2024 16:20:06] INFO - \n",
      "  | Name     | Type            | Params\n",
      "---------------------------------------------\n",
      "0 | reranker | BiEncoderRanker | 217 M \n",
      "1 | model    | BiEncoderModule | 217 M \n",
      "---------------------------------------------\n",
      "217 M     Trainable params\n",
      "0         Non-trainable params\n",
      "217 M     Total params\n",
      "870.586   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c468d23d02e242f1b23b75d50526720b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/Mar/2024 16:20:07] INFO - Eval: Dictionary: Embedding and building index\n",
      "[15/Mar/2024 16:20:07] INFO - Eval: Dictionary: Embedding and building index\n",
      "[15/Mar/2024 16:20:07] INFO - Eval: Dictionary: Embedding and building index\n",
      "[15/Mar/2024 16:20:07] INFO - Eval: Dictionary: Embedding and building index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding in batches: 100%|██████████| 104/104 [00:06<00:00, 15.13it/s]\n",
      "Embedding in batches:  99%|█████████▉| 103/104 [00:06<00:00, 15.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/Mar/2024 16:20:14] INFO - Eval: Queries: Embedding and building index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding in batches:   0%|          | 0/2 [00:00<?, ?it/s], 15.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/Mar/2024 16:20:14] INFO - Eval: Queries: Embedding and building index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding in batches: 100%|██████████| 104/104 [00:06<00:00, 15.00it/s]\n",
      "Embedding in batches:  42%|████▏     | 44/104 [00:06<00:08,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/Mar/2024 16:20:14] INFO - Eval: Queries: Embedding and building index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding in batches: 100%|██████████| 2/2 [00:00<00:00, 25.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/Mar/2024 16:20:14] INFO - Eval: Starting KNN search...\n",
      "[15/Mar/2024 16:20:14] INFO - Eval: Search finished\n",
      "[15/Mar/2024 16:20:14] INFO - Eval: Building graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding in batches: 100%|██████████| 2/2 [00:00<00:00, 25.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/Mar/2024 16:20:14] INFO - Eval: Starting KNN search...\n",
      "[15/Mar/2024 16:20:14] INFO - Eval: Search finished\n",
      "[15/Mar/2024 16:20:14] INFO - Eval: Building graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding in batches: 100%|██████████| 2/2 [00:00<00:00, 25.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/Mar/2024 16:20:14] INFO - Eval: Starting KNN search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: Building graphs: 100%|██████████| 200/200 [00:00<00:00, 3867.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/Mar/2024 16:20:14] INFO - \n",
      "Eval: Graph (k=0):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Paritioning joint graph: 100%|██████████| 200/200 [00:00<00:00, 102512.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/Mar/2024 16:20:14] INFO - Eval: Search finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding in batches:  43%|████▎     | 45/104 [00:07<00:08,  7.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/Mar/2024 16:20:14] INFO - Eval: Building graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: Building graphs: 100%|██████████| 200/200 [00:00<00:00, 4274.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/Mar/2024 16:20:14] INFO - \n",
      "Eval: Graph (k=0):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Paritioning joint graph: 100%|██████████| 200/200 [00:00<00:00, 105358.05it/s]\n",
      "Eval: Building graphs: 100%|██████████| 200/200 [00:00<00:00, 4187.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/Mar/2024 16:20:14] INFO - \n",
      "Eval: Graph (k=0):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Paritioning joint graph:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing clusters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Paritioning joint graph: 100%|██████████| 200/200 [00:00<00:00, 68775.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.0 %\n",
      "[15/Mar/2024 16:20:14] INFO - Eval: accuracy for graph@k=0: 0.0%\n",
      "[15/Mar/2024 16:20:14] INFO - \n",
      "Eval: Graph (k=1):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Paritioning joint graph:   0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing clusters..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Paritioning joint graph: 100%|██████████| 400/400 [00:00<00:00, 91091.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.0 %\n",
      "[15/Mar/2024 16:20:14] INFO - Eval: accuracy for graph@k=0: 0.0%\n",
      "[15/Mar/2024 16:20:14] INFO - \n",
      "Eval: Graph (k=1):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Paritioning joint graph: 100%|██████████| 400/400 [00:00<00:00, 100013.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing clusters...Analyzing clusters...\n",
      "\n",
      "Accuracy = 0.0 %\n",
      "[15/Mar/2024 16:20:14] INFO - Eval: accuracy for graph@k=1: 0.0%\n",
      "[15/Mar/2024 16:20:14] INFO - \n",
      "Eval: Graph (k=2):\n",
      "Accuracy = 0.0 %\n",
      "[15/Mar/2024 16:20:14] INFO - Eval: accuracy for graph@k=0: 0.0%\n",
      "[15/Mar/2024 16:20:14] INFO - \n",
      "Eval: Graph (k=1):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Paritioning joint graph: 100%|██████████| 600/600 [00:00<00:00, 55475.32it/s]\n",
      "Paritioning joint graph:   0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing clusters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Paritioning joint graph: 100%|██████████| 400/400 [00:00<00:00, 78142.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.0 %\n",
      "[15/Mar/2024 16:20:14] INFO - Eval: accuracy for graph@k=1: 0.0%\n",
      "[15/Mar/2024 16:20:14] INFO - \n",
      "Eval: Graph (k=2):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Paritioning joint graph: 100%|██████████| 600/600 [00:00<00:00, 71842.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing clusters...\n",
      "Accuracy = 0.0 %\n",
      "[15/Mar/2024 16:20:14] INFO - Eval: accuracy for graph@k=2: 0.0%\n",
      "[15/Mar/2024 16:20:14] INFO - \n",
      "Eval: Graph (k=4):\n",
      "Analyzing clusters...\n",
      "Accuracy = 0.0 %\n",
      "[15/Mar/2024 16:20:14] INFO - Eval: accuracy for graph@k=1: 0.0%\n",
      "[15/Mar/2024 16:20:14] INFO - \n",
      "Eval: Graph (k=2):\n",
      "Analyzing clusters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Paritioning joint graph:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.0 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Paritioning joint graph:   0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/Mar/2024 16:20:14] INFO - Eval: accuracy for graph@k=2: 0.0%\n",
      "[15/Mar/2024 16:20:14] INFO - \n",
      "Eval: Graph (k=4):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Paritioning joint graph: 100%|██████████| 1000/1000 [00:00<00:00, 57866.84it/s]\n",
      "Paritioning joint graph: 100%|██████████| 1000/1000 [00:00<00:00, 97632.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing clusters...\n",
      "Accuracy = 0.0 %\n",
      "[15/Mar/2024 16:20:14] INFO - Eval: accuracy for graph@k=2: 0.0%\n",
      "[15/Mar/2024 16:20:14] INFO - \n",
      "Eval: Graph (k=4):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Paritioning joint graph:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing clusters...\n",
      "Accuracy = 0.0 %"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding in batches:  45%|████▌     | 47/104 [00:07<00:08,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[15/Mar/2024 16:20:14] INFO - Eval: accuracy for graph@k=4: 0.0%\n",
      "[15/Mar/2024 16:20:14] INFO - \n",
      "Eval: Graph (k=8):\n",
      "Analyzing clusters..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Paritioning joint graph: 100%|██████████| 1000/1000 [00:00<00:00, 93310.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.0 %\n",
      "[15/Mar/2024 16:20:14] INFO - Eval: accuracy for graph@k=4: 0.0%\n",
      "[15/Mar/2024 16:20:14] INFO - \n",
      "Eval: Graph (k=8):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing clusters...\n",
      "Accuracy = 0.0 %\n",
      "[15/Mar/2024 16:20:14] INFO - Eval: accuracy for graph@k=4: 0.0%\n",
      "[15/Mar/2024 16:20:14] INFO - \n",
      "Eval: Graph (k=8):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Paritioning joint graph: 100%|██████████| 1800/1800 [00:00<00:00, 11912.72it/s]\n",
      "Paritioning joint graph: 100%|██████████| 1800/1800 [00:00<00:00, 11565.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing clusters...\n",
      "Accuracy = 0.0 %\n",
      "[15/Mar/2024 16:20:14] INFO - Eval: accuracy for graph@k=8: 0.0%\n",
      "[15/Mar/2024 16:20:14] INFO - Eval: Best accuracy: 0.0%\n",
      "Analyzing clusters...\n",
      "Accuracy = 0.0 %\n",
      "[15/Mar/2024 16:20:14] INFO - Eval: accuracy for graph@k=8: 0.0%\n",
      "[15/Mar/2024 16:20:14] INFO - Eval: Best accuracy: 0.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Paritioning joint graph: 100%|██████████| 1800/1800 [00:00<00:00, 10382.83it/s]\n",
      "/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:441: It is recommended to use `self.log('max_acc', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:441: It is recommended to use `self.log('dict_acc_k0', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:441: It is recommended to use `self.log('dict_acc_k1', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:441: It is recommended to use `self.log('dict_acc_k2', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:441: It is recommended to use `self.log('dict_acc_k4', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:441: It is recommended to use `self.log('dict_acc_k8', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:441: It is recommended to use `self.log('embed_and_index_dictk0', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:441: It is recommended to use `self.log('embed_and_index_dictk1', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:441: It is recommended to use `self.log('embed_and_index_dictk2', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:441: It is recommended to use `self.log('embed_and_index_dictk4', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:441: It is recommended to use `self.log('embed_and_index_dictk8', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing clusters...\n",
      "Accuracy = 0.0 %\n",
      "[15/Mar/2024 16:20:14] INFO - Eval: accuracy for graph@k=8: 0.0%\n",
      "[15/Mar/2024 16:20:14] INFO - Eval: Best accuracy: 0.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding in batches: 100%|██████████| 104/104 [00:15<00:00,  6.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/Mar/2024 16:20:22] INFO - Eval: Queries: Embedding and building index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding in batches: 100%|██████████| 2/2 [00:00<00:00,  9.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/Mar/2024 16:20:22] INFO - Eval: Starting KNN search...\n",
      "[15/Mar/2024 16:20:22] INFO - Eval: Search finished\n",
      "[15/Mar/2024 16:20:22] INFO - Eval: Building graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: Building graphs: 100%|██████████| 200/200 [00:00<00:00, 4289.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/Mar/2024 16:20:22] INFO - \n",
      "Eval: Graph (k=0):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Paritioning joint graph: 100%|██████████| 200/200 [00:00<00:00, 93175.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing clusters...\n",
      "Accuracy = 0.0 %\n",
      "[15/Mar/2024 16:20:23] INFO - Eval: accuracy for graph@k=0: 0.0%\n",
      "[15/Mar/2024 16:20:23] INFO - \n",
      "Eval: Graph (k=1):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Paritioning joint graph: 100%|██████████| 400/400 [00:00<00:00, 79093.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing clusters...\n",
      "Accuracy = 0.0 %\n",
      "[15/Mar/2024 16:20:23] INFO - Eval: accuracy for graph@k=1: 0.0%\n",
      "[15/Mar/2024 16:20:23] INFO - \n",
      "Eval: Graph (k=2):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Paritioning joint graph: 100%|██████████| 600/600 [00:00<00:00, 99152.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing clusters...\n",
      "Accuracy = 0.0 %\n",
      "[15/Mar/2024 16:20:23] INFO - Eval: accuracy for graph@k=2: 0.0%\n",
      "[15/Mar/2024 16:20:23] INFO - \n",
      "Eval: Graph (k=4):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Paritioning joint graph: 100%|██████████| 1000/1000 [00:00<00:00, 48660.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing clusters...\n",
      "Accuracy = 0.0 %\n",
      "[15/Mar/2024 16:20:23] INFO - Eval: accuracy for graph@k=4: 0.0%\n",
      "[15/Mar/2024 16:20:23] INFO - \n",
      "Eval: Graph (k=8):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Paritioning joint graph: 100%|██████████| 1800/1800 [00:00<00:00, 11425.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing clusters...\n",
      "Accuracy = 0.0 %\n",
      "[15/Mar/2024 16:20:23] INFO - Eval: accuracy for graph@k=8: 0.0%\n",
      "[15/Mar/2024 16:20:23] INFO - Eval: Best accuracy: 0.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "Embedding in batches:   0%|          | 0/104 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef67fd0e2e294857999a0d4a29a4995b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding in batches: 100%|██████████| 104/104 [00:05<00:00, 18.35it/s]\n",
      "Embedding in batches: 100%|██████████| 104/104 [00:05<00:00, 18.35it/s]\n",
      "Embedding in batches:  40%|████      | 42/104 [00:05<00:08,  7.28it/s]]\n",
      "Embedding in batches: 100%|██████████| 2/2 [00:00<00:00, 25.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/Mar/2024 16:20:29] INFO - Starting KNN search...\n",
      "[15/Mar/2024 16:20:29] INFO - Search finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding in batches: 100%|██████████| 2/2 [00:00<00:00, 25.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/Mar/2024 16:20:29] INFO - Starting KNN search...\n",
      "[15/Mar/2024 16:20:29] INFO - Search finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding in batches: 100%|██████████| 2/2 [00:00<00:00, 25.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/Mar/2024 16:20:29] INFO - Starting KNN search...\n",
      "[15/Mar/2024 16:20:29] INFO - Search finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding in batches:  41%|████▏     | 43/104 [00:05<00:08,  7.26it/s]/tmp/ipykernel_715265/1537706544.py:241: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
      "  negative_dict_inputs = torch.tensor(list(map(lambda x: self.trainer.datamodule.entity_dict_vecs[x].numpy(), negative_dict_inputs)))\n",
      "/tmp/ipykernel_715265/1537706544.py:241: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
      "  negative_dict_inputs = torch.tensor(list(map(lambda x: self.trainer.datamodule.entity_dict_vecs[x].numpy(), negative_dict_inputs)))\n",
      "/tmp/ipykernel_715265/1537706544.py:241: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
      "  negative_dict_inputs = torch.tensor(list(map(lambda x: self.trainer.datamodule.entity_dict_vecs[x].numpy(), negative_dict_inputs)))\n",
      "Embedding in batches:  44%|████▍     | 46/104 [00:06<00:08,  7.25it/s]INFO: [rank: 3] Received SIGTERM: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/Mar/2024 16:20:29] INFO - [rank: 3] Received SIGTERM: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding in batches: 100%|██████████| 104/104 [00:14<00:00,  7.21it/s]\n",
      "Embedding in batches: 100%|██████████| 2/2 [00:00<00:00,  9.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/Mar/2024 16:20:38] INFO - Starting KNN search...\n",
      "[15/Mar/2024 16:20:38] INFO - Search finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_715265/1537706544.py:241: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
      "  negative_dict_inputs = torch.tensor(list(map(lambda x: self.trainer.datamodule.entity_dict_vecs[x].numpy(), negative_dict_inputs)))\n"
     ]
    },
    {
     "ename": "ProcessRaisedException",
     "evalue": "\n\n-- Process 0 terminated with the following error:\nTraceback (most recent call last):\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/multiprocessing/spawn.py\", line 68, in _wrap\n    fn(i, *args)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/multiprocessing.py\", line 173, in _wrapping_function\n    results = function(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py\", line 579, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py\", line 986, in _run\n    results = self._run_stage()\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py\", line 1032, in _run_stage\n    self.fit_loop.run()\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n    self.advance()\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n    self.epoch_loop.run(self._data_fetcher)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 138, in run\n    self.advance(data_fetcher)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 242, in advance\n    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 191, in run\n    self._optimizer_step(batch_idx, closure)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 269, in _optimizer_step\n    call._call_lightning_module_hook(\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py\", line 157, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/core/module.py\", line 1303, in optimizer_step\n    optimizer.step(closure=optimizer_closure)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/core/optimizer.py\", line 152, in step\n    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/strategies/ddp.py\", line 270, in optimizer_step\n    optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/strategies/strategy.py\", line 239, in optimizer_step\n    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n    return optimizer.step(closure=closure, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/optim/lr_scheduler.py\", line 75, in wrapper\n    return wrapped(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 385, in wrapper\n    out = func(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/pytorch_transformers/optimization.py\", line 139, in step\n    loss = closure()\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n    closure_result = closure()\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n    self._result = self.closure(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n    return func(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 129, in closure\n    step_output = self._step_fn()\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 319, in _training_step\n    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py\", line 309, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/strategies/strategy.py\", line 390, in training_step\n    return self._forward_redirection(self.model, self.lightning_module, \"training_step\", *args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/strategies/strategy.py\", line 642, in __call__\n    wrapper_output = wrapper_module(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/nn/parallel/distributed.py\", line 1523, in forward\n    else self._run_ddp_forward(*inputs, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/nn/parallel/distributed.py\", line 1359, in _run_ddp_forward\n    return self.module(*inputs, **kwargs)  # type: ignore[index]\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/strategies/strategy.py\", line 635, in wrapped_forward\n    out = method(*_args, **_kwargs)\n  File \"/tmp/ipykernel_715265/1537706544.py\", line 281, in training_step\n    f = self.forward(batch_context_inputs, candidate_idxs, n_gold, mention_idxs)\n  File \"/tmp/ipykernel_715265/1537706544.py\", line 250, in forward\n    pos_embed = self.reranker.encode_candidate(self.trainer.datamodule.entity_dict_vecs[pos_idx:pos_idx + 1], requires_grad=True)\n  File \"/home2/cye73/arboEL/blink/biencoder/../../blink/biencoder/biencoder.py\", line 238, in encode_candidate\n    _, embedding_cands = self.model(\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home2/cye73/arboEL/blink/biencoder/../../blink/biencoder/biencoder.py\", line 90, in forward\n    embedding_cands = self.cand_encoder(\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home2/cye73/arboEL/blink/biencoder/../../blink/common/ranker_base.py\", line 43, in forward\n    output_bert, output_pooler = self.bert_model(\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\", line 1006, in forward\n    embedding_output = self.embeddings(\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\", line 232, in forward\n    inputs_embeds = self.word_embeddings(input_ids)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/nn/modules/sparse.py\", line 163, in forward\n    return F.embedding(\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/nn/functional.py\", line 2237, in embedding\n    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProcessRaisedException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [81], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_module\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py:543\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 543\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py:43\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlauncher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/multiprocessing.py:144\u001b[0m, in \u001b[0;36m_MultiProcessingLauncher.launch\u001b[0;34m(self, function, trainer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m process_context \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39mstart_processes(\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrapping_function,\n\u001b[1;32m    138\u001b[0m     args\u001b[38;5;241m=\u001b[39mprocess_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m     join\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,  \u001b[38;5;66;03m# we will join ourselves to get the process references\u001b[39;00m\n\u001b[1;32m    142\u001b[0m )\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocs \u001b[38;5;241m=\u001b[39m process_context\u001b[38;5;241m.\u001b[39mprocesses\n\u001b[0;32m--> 144\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mprocess_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    147\u001b[0m worker_output \u001b[38;5;241m=\u001b[39m return_queue\u001b[38;5;241m.\u001b[39mget()\n",
      "File \u001b[0;32m/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/multiprocessing/spawn.py:158\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    156\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-- Process \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with the following error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m error_index\n\u001b[1;32m    157\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m original_trace\n\u001b[0;32m--> 158\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ProcessRaisedException(msg, error_index, failed_process\u001b[38;5;241m.\u001b[39mpid)\n",
      "\u001b[0;31mProcessRaisedException\u001b[0m: \n\n-- Process 0 terminated with the following error:\nTraceback (most recent call last):\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/multiprocessing/spawn.py\", line 68, in _wrap\n    fn(i, *args)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/multiprocessing.py\", line 173, in _wrapping_function\n    results = function(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py\", line 579, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py\", line 986, in _run\n    results = self._run_stage()\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py\", line 1032, in _run_stage\n    self.fit_loop.run()\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n    self.advance()\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n    self.epoch_loop.run(self._data_fetcher)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 138, in run\n    self.advance(data_fetcher)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 242, in advance\n    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 191, in run\n    self._optimizer_step(batch_idx, closure)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 269, in _optimizer_step\n    call._call_lightning_module_hook(\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py\", line 157, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/core/module.py\", line 1303, in optimizer_step\n    optimizer.step(closure=optimizer_closure)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/core/optimizer.py\", line 152, in step\n    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/strategies/ddp.py\", line 270, in optimizer_step\n    optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/strategies/strategy.py\", line 239, in optimizer_step\n    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n    return optimizer.step(closure=closure, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/optim/lr_scheduler.py\", line 75, in wrapper\n    return wrapped(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 385, in wrapper\n    out = func(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/pytorch_transformers/optimization.py\", line 139, in step\n    loss = closure()\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n    closure_result = closure()\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n    self._result = self.closure(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n    return func(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 129, in closure\n    step_output = self._step_fn()\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 319, in _training_step\n    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py\", line 309, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/strategies/strategy.py\", line 390, in training_step\n    return self._forward_redirection(self.model, self.lightning_module, \"training_step\", *args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/strategies/strategy.py\", line 642, in __call__\n    wrapper_output = wrapper_module(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/nn/parallel/distributed.py\", line 1523, in forward\n    else self._run_ddp_forward(*inputs, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/nn/parallel/distributed.py\", line 1359, in _run_ddp_forward\n    return self.module(*inputs, **kwargs)  # type: ignore[index]\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/lightning/pytorch/strategies/strategy.py\", line 635, in wrapped_forward\n    out = method(*_args, **_kwargs)\n  File \"/tmp/ipykernel_715265/1537706544.py\", line 281, in training_step\n    f = self.forward(batch_context_inputs, candidate_idxs, n_gold, mention_idxs)\n  File \"/tmp/ipykernel_715265/1537706544.py\", line 250, in forward\n    pos_embed = self.reranker.encode_candidate(self.trainer.datamodule.entity_dict_vecs[pos_idx:pos_idx + 1], requires_grad=True)\n  File \"/home2/cye73/arboEL/blink/biencoder/../../blink/biencoder/biencoder.py\", line 238, in encode_candidate\n    _, embedding_cands = self.model(\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home2/cye73/arboEL/blink/biencoder/../../blink/biencoder/biencoder.py\", line 90, in forward\n    embedding_cands = self.cand_encoder(\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home2/cye73/arboEL/blink/biencoder/../../blink/common/ranker_base.py\", line 43, in forward\n    output_bert, output_pooler = self.bert_model(\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\", line 1006, in forward\n    embedding_output = self.embeddings(\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\", line 232, in forward\n    inputs_embeds = self.word_embeddings(input_ids)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/nn/modules/sparse.py\", line 163, in forward\n    return F.embedding(\n  File \"/nethome/cye73/conda_envs/arboel_2/lib/python3.9/site-packages/torch/nn/functional.py\", line 2237, in embedding\n    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, datamodule=data_module )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arboel_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
